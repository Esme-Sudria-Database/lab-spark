---
- name: ensure openjdk is setup
  package:
    name: openjdk-8-jdk
    state: present

- name: ensure scala is setup
  package:
    name: scala
    state: present

- name: ensure package is downloaded
  get_url:
    url: "http://apache.crihan.fr/dist/spark/{{ spark_package }}/{{ spark_package }}-bin-hadoop2.7.tgz"
    dest: "/tmp/{{ spark_package }}.zip"
    mode: 0755

- name: ensure /opt/spark directory exists
  file:
    path: /opt/spark
    state: directory

- name: ensure spark is unpacked
  unarchive:
    src: "/tmp/{{ spark_package }}.zip"
    dest: /opt/spark
    remote_src: true

- name: ensure spark-shell is a link
  file:
    src: "/opt/spark/{{ spark_directory }}/bin/spark-shell"
    dest: "/usr/local/bin/spark-shell"
    state: link

- name: ensure pyspark is a link
  file:
    src: "/opt/spark/{{ spark_directory }}/bin/pyspark"
    dest: "/usr/local/bin/pyspark"
    state: link

- name: ensure spark-shell requirements are available on path
  file:
    src: "/opt/spark/{{ spark_directory }}/bin/{{ item }}"
    dest: "/usr/local/bin/{{ item }}"
    state: link
  with_items:
    - find-spark-home
    - spark-submit
    - spark-class

- name: ensure SPARK_HOME is set as environment variable
  lineinfile:
    dest: /etc/environment
    regexp: "^export SPARK_HOME="
    line: "export SPARK_HOME=\"/opt/spark/{{ spark_directory }}\""
    state: present
